{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Monte Carlo Simulation and Density Functions Notebook\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "\n",
    "- Read and preprocess a dataset.\n",
    "- Compute empirical CDFs for each month and hour.\n",
    "- Simulate daily profiles using the inverse CDF method.\n",
    "- Cluster the simulated profiles with KMeans.\n",
    "- Save and visualize representative daily profiles.\n",
    "- Plot density functions (Kernel Density Estimation) for each hour of a selected month.\n",
    "\n",
    "Make sure the CSV file (`Timeseries_2005_2023.csv`) is available in the working directory."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import gaussian_kde\n",
    "import csv\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Parameters\n",
    "dataset_path = 'data/Solar_Timeseries_2005_2023.csv'\n",
    "clusters_per_month = 5\n",
    "n_simulations = 1000\n",
    "example_month = 7"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Reading and Preprocessing the Dataset\n",
    "\n",
    "The following function reads the CSV file and preprocesses the data by converting the time column and adding additional columns."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def read_and_prepare_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Reads the dataset and preprocesses it.\n",
    "    \n",
    "    Parameters:\n",
    "        dataset_path (str): Path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame with additional columns (month, hour, date).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%Y%m%d:%H%M')\n",
    "    df.rename(columns={\n",
    "        \"G(i) (Globalstrahlung)\": \"global_radiation\",\n",
    "        \"H_sun (Sonnenscheindauer in min)\": \"sunshine_duration\",\n",
    "        \"T2m (Temperatur)\": \"temperature\",\n",
    "        \"WS10m (Windgeschwindigkeit)\": \"wind_speed\"\n",
    "    }, inplace=True)\n",
    "    df['month'] = df['time'].dt.month\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['date'] = df['time'].dt.date\n",
    "    return df\n",
    "\n",
    "# 1. Read and preprocess dataset\n",
    "df = read_and_prepare_dataset(dataset_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Compute Empirical CDF Lookup\n",
    "\n",
    "The following function computes a lookup dictionary for each month and hour containing the sorted data and its empirical CDF."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_cdf_lookup(df):\n",
    "    \"\"\"\n",
    "    Computes the sorted measurements and the corresponding empirical CDF for each month and hour.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Preprocessed dataset.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: A lookup dictionary in the form {month: {hour: (sorted_data, cdf)}} and a sorted list of months.\n",
    "    \"\"\"\n",
    "    cdf_lookup = {}\n",
    "    months = sorted(df['month'].unique())\n",
    "    for month in months:\n",
    "        cdf_lookup[month] = {}\n",
    "        for hour in range(24):\n",
    "            hour_data = df[(df['month'] == month) & (df['hour'] == hour)]['temperature'].dropna().values\n",
    "            if len(hour_data) == 0:\n",
    "                continue\n",
    "            sorted_data = np.sort(hour_data)\n",
    "            cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "            cdf_lookup[month][hour] = (sorted_data, cdf)\n",
    "    return cdf_lookup, months\n",
    "\n",
    "\n",
    "# 2. Compute the empirical CDF for each month and hour\n",
    "cdf_lookup, months = compute_cdf_lookup(df)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Save CDF Lookup to CSV"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import csv\n",
    "\n",
    "def save_cdf_lookup_to_csv(cdf_lookup, filename=\"data/saved_csv/CDF_Functions_Temperature.csv\"):\n",
    "    \"\"\"\n",
    "    Speichert das CDF Lookup Dictionary in einer CSV-Datei mit der ursprünglichen Header-Struktur.\n",
    "\n",
    "    Parameter:\n",
    "        cdf_lookup (dict): Dictionary mit den CDF Lookup-Werten.\n",
    "        filename (str): Name der CSV-Datei zum Speichern.\n",
    "    \"\"\"\n",
    "    # Header mit Spaltennamen \"CDFs\" + \"Month_X_Hour_Y\"\n",
    "    header = [\"CDFs\"] + [f\"Month_{month}_Hour_{hour}\" for month in range(1, 13) for hour in range(24)]\n",
    "\n",
    "    # Die erste Spalte enthält \"Temperature_CDF\" als Bezeichnung\n",
    "    data_row = [\"Temperature_CDF\"]\n",
    "\n",
    "    # Temperaturwerte für jede Monats-Stunde-Kombination einfügen\n",
    "    for month in range(1, 13):\n",
    "        for hour in range(24):\n",
    "            sorted_data, _ = cdf_lookup.get(month, {}).get(hour, ([], []))\n",
    "            sorted_data_str = \";\".join(map(str, sorted_data))  # Werte mit Semikolon trennen für bessere CSV-Kompatibilität\n",
    "            data_row.append(sorted_data_str)\n",
    "\n",
    "    # CSV schreiben\n",
    "    with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(header)\n",
    "        writer.writerow(data_row)\n",
    "\n",
    "    return filename  # Return the filename for confirmation\n",
    "\n",
    "# 2.1. Save the CDF lookup to a CSV file\n",
    "save_cdf_lookup_to_csv(cdf_lookup)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix: 3. Simulate Daily Profiles\n",
    "\n",
    "This function simulates daily profiles for a given month using the inverse CDF method."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def simulate_daily_profile(month, cdf_lookup, n_simulations=1000):\n",
    "    \"\"\"\n",
    "    Simulates daily profiles for a given month using the inverse CDF method.\n",
    "    \n",
    "    Parameters:\n",
    "        month (int): The month for which to simulate.\n",
    "        cdf_lookup (dict): Lookup dictionary with the CDF values.\n",
    "        n_simulations (int): Number of simulations.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: Array with simulated daily profiles (each row contains 24 hourly values).\n",
    "    \"\"\"\n",
    "    daily_profiles = []\n",
    "    for _ in range(n_simulations):\n",
    "        profile = []\n",
    "        for hour in range(24):\n",
    "            if hour in cdf_lookup[month]:\n",
    "                sorted_data, cdf = cdf_lookup[month][hour]\n",
    "                u = np.random.uniform(0, 1)\n",
    "                # Inverse CDF via interpolation\n",
    "                value = np.interp(u, cdf, sorted_data)\n",
    "                profile.append(value)\n",
    "            else:\n",
    "                profile.append(np.nan)\n",
    "        daily_profiles.append(profile)\n",
    "    return np.array(daily_profiles)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix: 4. Cluster Simulated Profiles using KMeans\n",
    "\n",
    "The following function clusters the simulated daily profiles using the KMeans algorithm."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cluster_profiles(simulated_profiles, clusters_per_month=5):\n",
    "    \"\"\"\n",
    "    Clusters the simulated daily profiles using KMeans.\n",
    "    \n",
    "    Parameters:\n",
    "        simulated_profiles (np.array): Array of simulated profiles.\n",
    "        clusters_per_month (int): Number of clusters per month.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of cluster results with cluster ID, representative profile, and probability.\n",
    "    \"\"\"\n",
    "    kmeans = KMeans(n_clusters=clusters_per_month, random_state=42).fit(simulated_profiles)\n",
    "    labels = kmeans.labels_\n",
    "    centers = kmeans.cluster_centers_\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    cluster_probs = {cl: count / simulated_profiles.shape[0] for cl, count in zip(unique, counts)}\n",
    "\n",
    "    clusters = []\n",
    "    for cl in unique:\n",
    "        clusters.append({\n",
    "            'cluster': int(cl),\n",
    "            'profile': centers[cl].tolist(),\n",
    "            'probability': cluster_probs[cl]\n",
    "        })\n",
    "    return clusters"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Appendix: Monte Carlo simulation and scenario reduction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 3. Monte Carlo simulation and scenario reduction\n",
    "rep_profiles = []  # List to store representative profiles\n",
    "for month in months:\n",
    "    print(f\"Simulating and clustering for month {month} ...\")\n",
    "    simulated_profiles = simulate_daily_profile(month, cdf_lookup, n_simulations)\n",
    "    #OUTPUT: shape (\"n_simulations\", 24) for month \"month\"\n",
    "    # Skip if there is not enough data\n",
    "    if simulated_profiles.shape[0] < clusters_per_month:\n",
    "        continue\n",
    "    clusters = cluster_profiles(simulated_profiles, clusters_per_month)\n",
    "    for cl in clusters:\n",
    "        cl['month'] = month\n",
    "        rep_profiles.append(cl)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix: 5. Save Representative Daily Profiles\n",
    "\n",
    "This function saves the representative profiles to a CSV file. The profiles are expanded into 24 separate columns."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_representative_profiles(rep_profiles, filename='data/saved_csv/temperature_representative_daily_profiles_all_months.csv'):\n",
    "    \"\"\"\n",
    "    Saves the representative daily profiles to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        rep_profiles (list): List of representative profiles.\n",
    "        filename (str): Filename for saving.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame of representative profiles with hourly columns separated.\n",
    "    \"\"\"\n",
    "    rep_df = pd.DataFrame(rep_profiles)\n",
    "    # Split the 'profile' column into 24 separate columns\n",
    "    profile_df = rep_df['profile'].apply(pd.Series)\n",
    "    profile_df.columns = [f'hour_{h}' for h in range(24)]\n",
    "    rep_df = pd.concat([rep_df.drop(columns=['profile']), profile_df], axis=1)\n",
    "    rep_df.sort_values(by=['month', 'cluster'], inplace=True)\n",
    "    rep_df.to_csv(filename, index=False)\n",
    "    print(f\"Representative daily profiles have been saved to '{filename}'.\")\n",
    "    return rep_df\n",
    "\n",
    "# 4. Save representative profiles\n",
    "rep_df = save_representative_profiles(rep_profiles)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix: 6. Visualize Representative Daily Profiles\n",
    "\n",
    "This function plots the representative daily profiles for a specified month."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_profiles_for_month(rep_df, month):\n",
    "    \"\"\"\n",
    "    Visualizes the representative daily profiles for a given month.\n",
    "    \n",
    "    Parameters:\n",
    "        rep_df (pd.DataFrame): DataFrame of representative profiles.\n",
    "        month (int): The month to visualize.\n",
    "    \"\"\"\n",
    "    month_profiles = rep_df[rep_df['month'] == month]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    hours = np.arange(24)\n",
    "    for _, row in month_profiles.iterrows():\n",
    "        values = row[[f'hour_{h}' for h in hours]]\n",
    "        plt.plot(hours, values, marker='o', label=f\"Cluster {row['cluster']} (p={row['probability']:.2f})\")\n",
    "    plt.xlabel('Hour of the day')\n",
    "    plt.ylabel('Temperature')\n",
    "    plt.title(f'Representative Daily Profiles for Month {month}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# 5. Visualize representative profiles for an example month\n",
    "plot_profiles_for_month(rep_df, example_month)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Appendix: 7. Plot Density Functions for Each Hour\n",
    "\n",
    "The following function plots the density functions (using Kernel Density Estimation) for each hour of a given month. If the data for an hour has insufficient variability, a message is shown instead.\n",
    "There are two versions of the function: one with the original x-axis scaling and one with a normalized x-axis scaling (0 to 1)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_density_functions_for_month(df, month):\n",
    "    \"\"\"\n",
    "    Plots the density functions (Kernel Density Estimation) for each hour of a given month.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Preprocessed dataset.\n",
    "        month (int): The month for which to plot the density functions.\n",
    "    \"\"\"\n",
    "    # Create a 4x6 grid for 24 subplots\n",
    "    fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for hour in range(24):\n",
    "        ax = axes[hour]\n",
    "        # Filter data for the given month and hour\n",
    "        hour_data = df[(df['month'] == month) & (df['hour'] == hour)]['temperature'].dropna().values\n",
    "\n",
    "        if len(hour_data) == 0:\n",
    "            ax.set_title(f\"Hour {hour}\\n(no data)\")\n",
    "            ax.set_xlabel('Temperature')\n",
    "            ax.set_ylabel('Density')\n",
    "            continue\n",
    "\n",
    "        # Check if the data has enough variability\n",
    "        if len(np.unique(hour_data)) < 2:\n",
    "            constant_value = hour_data[0]\n",
    "            ax.axvline(constant_value, color='red', linestyle='--', label=\"Constant value\")\n",
    "            ax.set_title(f\"Hour {hour}\\n(constant)\")\n",
    "            ax.set_xlabel('Temperature')\n",
    "            ax.set_ylabel('Density')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            continue\n",
    "\n",
    "        # Compute the Kernel Density Estimation\n",
    "        try:\n",
    "            kde = gaussian_kde(hour_data)\n",
    "            x_min = hour_data.min() - 0.1 * abs(hour_data.min())\n",
    "            x_max = hour_data.max() + 0.1 * abs(hour_data.max())\n",
    "            x_grid = np.linspace(x_min, x_max, 100)\n",
    "            density = kde(x_grid)\n",
    "            ax.plot(x_grid, density, color='blue')\n",
    "        except np.linalg.LinAlgError:\n",
    "            ax.text(0.5, 0.5, \"KDE Error\", transform=ax.transAxes, ha='center')\n",
    "        \n",
    "        ax.set_title(f\"Hour {hour}\")\n",
    "        ax.set_xlabel('Temperature')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.set_xlim(0, 38.5)\n",
    "        ax.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Density Functions for Month {month}', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# 6. Visualize density functions for each hour of the example month\n",
    "plot_density_functions_for_month(df, example_month)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_density_functions_for_month_normalized(df, month):\n",
    "    \"\"\"\n",
    "    Plots the density functions (Kernel Density Estimation) for each hour of a given month\n",
    "    with a uniform x-axis scaling (0 to 1). The y-axis remains unberührt und passt sich\n",
    "    der berechneten Dichte an.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Vorgefilterter Datensatz.\n",
    "        month (int): Der Monat, für den die Dichtefunktionen geplottet werden sollen.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy.stats import gaussian_kde\n",
    "\n",
    "    # Bestimme den maximalen Temperatur Wert für die Normierung\n",
    "    global_max = df['temperature'].max()\n",
    "\n",
    "    # Erstelle ein 4x6 Grid für 24 Subplots\n",
    "    fig, axes = plt.subplots(4, 6, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for hour in range(24):\n",
    "        ax = axes[hour]\n",
    "        # Filtere die Daten für den angegebenen Monat und die Stunde\n",
    "        hour_data = df[(df['month'] == month) & (df['hour'] == hour)]['temperature'].dropna().values\n",
    "\n",
    "        # Falls keine Daten vorhanden sind\n",
    "        if len(hour_data) == 0:\n",
    "            ax.set_title(f\"Hour {hour}\\n(no data)\")\n",
    "            ax.set_xlabel('Normalized Temperature')\n",
    "            ax.set_ylabel('Density')\n",
    "            ax.set_xlim(0, 1)\n",
    "            continue\n",
    "\n",
    "        # Falls die Daten keine Variation aufweisen (konstanter Wert)\n",
    "        if len(np.unique(hour_data)) < 2:\n",
    "            constant_value = hour_data[0]\n",
    "            # Normiere den konstanten Wert für die x-Achse\n",
    "            ax.axvline(constant_value / global_max, color='red', linestyle='--', label=\"Constant value\")\n",
    "            ax.set_title(f\"Hour {hour}\\n(constant)\")\n",
    "            ax.set_xlabel('Normalized Temperature')\n",
    "            ax.set_ylabel('Density')\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            ax.set_xlim(0, 1)\n",
    "            continue\n",
    "\n",
    "        # Berechne die Kernel Density Estimation (KDE)\n",
    "        try:\n",
    "            kde = gaussian_kde(hour_data)\n",
    "            # Erstelle einen normierten x-Bereich von 0 bis 1\n",
    "            x_grid_norm = np.linspace(0, 1, 100)\n",
    "            # Wandle in den Originalbereich um\n",
    "            x_grid_original = x_grid_norm * global_max\n",
    "            density = kde(x_grid_original)\n",
    "            ax.plot(x_grid_norm, density, color='blue')\n",
    "        except np.linalg.LinAlgError:\n",
    "            ax.text(0.5, 0.5, \"KDE Error\", transform=ax.transAxes, ha='center')\n",
    "\n",
    "        ax.set_title(f\"Hour {hour}\")\n",
    "        ax.set_xlabel('Normalized Temperature')\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.grid(True)\n",
    "        # Setze die x-Achse immer auf den Bereich [0, 1]\n",
    "        ax.set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Density Functions for Month {month}', fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 7. Visualize density functions for each hour of the example month with normalized x-axis\n",
    "plot_density_functions_for_month_normalized(df, example_month)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
